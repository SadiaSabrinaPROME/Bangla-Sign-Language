{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce05f997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '00': 1, '000': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'Counting': 12, 'S10_ko_CC': 13, 'S11_Kho_CC': 14, 'S12_go_CC': 15, 'S13_gho_CC': 16, 'S14_Umo_CC': 17, 'S15_co_CC': 18, 'S16_Cho_CC': 19, 'S17_jo_CC': 20, 'S18_jho_CC': 21, 'S19_Io_CC': 22, 'S1_o_CC': 23, 'S20_To_CC': 24, 'S21_THo_CC': 25, 'S22_Do_CC': 26, 'S23_Dho_CC': 27, 'S24_no_CC': 28, 'S25_to_CC': 29, 'S26_tho_CC': 30, 'S27_do_CC': 31, 'S28_dho_CC': 32, 'S29_po_CC': 33, 'S2_a_CC': 34, 'S30_fo_CC': 35, 'S31_bo_CC': 36, 'S32_mo_CC': 37, 'S33_lo_CC': 38, 'S34_so_CC': 39, 'S35_ho_CC': 40, 'S36_onnosar_CC': 41, 'S37_bissorgo_CC': 42, 'S38_Chandrabindu_CC': 43, 'S3_i_CC': 44, 'S4_u_CC': 45, 'S5_ro_CC': 46, 'S6_e_CC': 47, 'S7_Oi_CC': 48, 'S8_O_CC': 49, 'S9_OU_CC': 50, 'Sign 10_ Gho': 51, 'Sign 11_co': 52, 'Sign 12_cho': 53, 'Sign 13_jo': 54, 'Sign 14_Jho': 55, 'Sign 15_To': 56, 'Sign 16_THo': 57, 'Sign 17_DO': 58, 'Sign 18_DHO': 59, 'Sign 19_to': 60, 'Sign 1_o': 61, 'Sign 20_tho': 62, 'Sign 21_do': 63, 'Sign 22_dho': 64, 'Sign 23_po': 65, 'Sign 24_fo': 66, 'Sign 25_bo': 67, 'Sign 26_bho': 68, 'Sign 27_mo': 69, 'Sign 28_yo': 70, 'Sign 29_ro': 71, 'Sign 2_a': 72, 'Sign 30_lo': 73, 'Sign 31_so': 74, 'Sign 32_ho': 75, 'Sign 33_RO': 76, 'Sign 34_RHo': 77, 'Sign 35_onosshar': 78, 'Sign 36_bishorgo': 79, 'Sign 3_O': 80, 'Sign 4_U': 81, 'Sign 5_e': 82, 'Sign 6_I': 83, 'Sign 7_ko': 84, 'Sign 8_kho': 85, 'Sign 9_go': 86}\n",
      "['0', '00', '000', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Counting', 'S10_ko_CC', 'S11_Kho_CC', 'S12_go_CC', 'S13_gho_CC', 'S14_Umo_CC', 'S15_co_CC', 'S16_Cho_CC', 'S17_jo_CC', 'S18_jho_CC', 'S19_Io_CC', 'S1_o_CC', 'S20_To_CC', 'S21_THo_CC', 'S22_Do_CC', 'S23_Dho_CC', 'S24_no_CC', 'S25_to_CC', 'S26_tho_CC', 'S27_do_CC', 'S28_dho_CC', 'S29_po_CC', 'S2_a_CC', 'S30_fo_CC', 'S31_bo_CC', 'S32_mo_CC', 'S33_lo_CC', 'S34_so_CC', 'S35_ho_CC', 'S36_onnosar_CC', 'S37_bissorgo_CC', 'S38_Chandrabindu_CC', 'S3_i_CC', 'S4_u_CC', 'S5_ro_CC', 'S6_e_CC', 'S7_Oi_CC', 'S8_O_CC', 'S9_OU_CC', 'Sign 10_ Gho', 'Sign 11_co', 'Sign 12_cho', 'Sign 13_jo', 'Sign 14_Jho', 'Sign 15_To', 'Sign 16_THo', 'Sign 17_DO', 'Sign 18_DHO', 'Sign 19_to', 'Sign 1_o', 'Sign 20_tho', 'Sign 21_do', 'Sign 22_dho', 'Sign 23_po', 'Sign 24_fo', 'Sign 25_bo', 'Sign 26_bho', 'Sign 27_mo', 'Sign 28_yo', 'Sign 29_ro', 'Sign 2_a', 'Sign 30_lo', 'Sign 31_so', 'Sign 32_ho', 'Sign 33_RO', 'Sign 34_RHo', 'Sign 35_onosshar', 'Sign 36_bishorgo', 'Sign 3_O', 'Sign 4_U', 'Sign 5_e', 'Sign 6_I', 'Sign 7_ko', 'Sign 8_kho', 'Sign 9_go']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]\n"
     ]
    }
   ],
   "source": [
    "import  cv2,os\n",
    "from PIL import Image \n",
    "from PIL import Image, ImageOps \n",
    "data_path=r'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\BdSL-D1500\\BdSL-D1500'\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels))\n",
    "\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728614a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as skmetrics\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from PIL import ImageTk, Image\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL import Image, ImageFilter \n",
    "from PIL import Image, ImageOps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65c8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "#os.chdir('C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\BdSL-D1500\\BdSL-D1500')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdaa2fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: split-folders in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7473ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5542 files [00:06, 1037.64 files/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8580\\1286906928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msplitfolders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\BdSL-D1500\\BdSL-D1500'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1337\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36mratio\u001b[1;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclass_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         split_class_dir_ratio(\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36msplit_class_dir_ratio\u001b[1;34m(class_dir, output, ratio, seed, prog_bar, group_prefix, move)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[0mli\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_train_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_val_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[0mcopy_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36mcopy_files\u001b[1;34m(files_type, class_dir, output, prog_bar, move)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                 \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopystat\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[0m_copyxattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chmod\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;31m# if we got a NotImplementedError, it's because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(r'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\BdSL-D1500\\BdSL-D1500', output=\"Dataset\", seed=1337, ratio=(0.7, 0.2,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8708c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102e8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY = r'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\Dataset\\train'\n",
    "VAL_DIRECTORY = r'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\Dataset\\val'\n",
    "TEST_DIRECTORY = r'C:\\Users\\Dell\\Desktop\\499\\dataset bangla\\Dataset\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211f2013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '00', '000', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Counting', 'S10_ko_CC', 'S11_Kho_CC', 'S12_go_CC', 'S13_gho_CC', 'S14_Umo_CC', 'S15_co_CC', 'S16_Cho_CC', 'S17_jo_CC', 'S18_jho_CC', 'S19_Io_CC', 'S1_o_CC', 'S20_To_CC', 'S21_THo_CC', 'S22_Do_CC', 'S23_Dho_CC', 'S24_no_CC', 'S25_to_CC', 'S26_tho_CC', 'S27_do_CC', 'S28_dho_CC', 'S29_po_CC', 'S2_a_CC', 'S30_fo_CC', 'S31_bo_CC', 'S32_mo_CC', 'S33_lo_CC', 'S34_so_CC', 'S35_ho_CC', 'S36_onnosar_CC', 'S37_bissorgo_CC', 'S38_Chandrabindu_CC', 'S3_i_CC', 'S4_u_CC', 'S5_ro_CC', 'S6_e_CC', 'S7_Oi_CC', 'S8_O_CC', 'S9_OU_CC', 'Sign 10_ Gho', 'Sign 11_co', 'Sign 12_cho', 'Sign 13_jo', 'Sign 14_Jho', 'Sign 15_To', 'Sign 16_THo', 'Sign 17_DO', 'Sign 18_DHO', 'Sign 19_to', 'Sign 1_o', 'Sign 20_tho', 'Sign 21_do', 'Sign 22_dho', 'Sign 23_po', 'Sign 24_fo', 'Sign 25_bo', 'Sign 26_bho', 'Sign 27_mo', 'Sign 28_yo', 'Sign 29_ro', 'Sign 2_a', 'Sign 30_lo', 'Sign 31_so', 'Sign 32_ho', 'Sign 33_RO', 'Sign 34_RHo', 'Sign 35_onosshar', 'Sign 36_bishorgo', 'Sign 3_O', 'Sign 4_U', 'Sign 5_e', 'Sign 6_I', 'Sign 7_ko', 'Sign 8_kho', 'Sign 9_go']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(TRAIN_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b7ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05be034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c4f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_data = ImageFolder(TRAIN_DIRECTORY, transform=img_transform)\n",
    "val_data = ImageFolder(VAL_DIRECTORY, transform=img_transform)\n",
    "test_data = ImageFolder(TEST_DIRECTORY, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62df3e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92439\n",
      "26409\n",
      "92439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c2bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size*2, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, batch_size*2, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_data, batch_size*2,shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863ad180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#load pretrained model\n",
    "import torchvision.models as models\n",
    "\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# model = models.alexnet(pretrained=True)\n",
    "# model = models.squeezenet1_0(pretrained=True)\n",
    "# model = models.vgg16(pretrained=True)\n",
    "# model = models.densenet161(pretrained=True)\n",
    "# model = models.inception_v3(pretrained=True)\n",
    "# model = models.googlenet(pretrained=True)\n",
    "# model = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# model = models.wide_resnet50_2(pretrained=True)\n",
    "# model = models.mnasnet1_0(pretrained=True)\n",
    "\n",
    "#in_features\n",
    "# resnet18 = 1000\n",
    "# alexnet = 256*6*6\n",
    "# squeezenet1_0 = 1000\n",
    "#vgg16 = 512*7*7\n",
    "# densenet161\n",
    "# inception_v3\n",
    "# googlenet = 1000\n",
    "# shufflenet_v2_x1_0 = 1000\n",
    "mobilenet_v2 = 1280\n",
    "# resnext50_32x4d = 1000\n",
    "# wide_resnet50_2 = 1000\n",
    "# mnasnet1_0 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199fa694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=128, out_features=87, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier = nn.Sequential(nn.Linear(in_features=mobilenet_v2, out_features=256, bias=True),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True),\n",
    "                                 nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True),\n",
    "                                 nn.Linear(in_features=128, out_features=87, bias=True))\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7697c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56101be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [200/925], Loss: 4.3936\n",
      "Epoch [1/5], Step [400/925], Loss: 3.9007\n",
      "Epoch [1/5], Step [600/925], Loss: 3.4983\n",
      "Epoch [1/5], Step [800/925], Loss: 2.8641\n",
      "Epoch [2/5], Step [200/925], Loss: 1.9403\n",
      "Epoch [2/5], Step [400/925], Loss: 1.6172\n",
      "Epoch [2/5], Step [600/925], Loss: 1.5410\n",
      "Epoch [2/5], Step [800/925], Loss: 1.0939\n",
      "Epoch [3/5], Step [200/925], Loss: 0.8982\n",
      "Epoch [3/5], Step [400/925], Loss: 0.7067\n",
      "Epoch [3/5], Step [600/925], Loss: 0.5799\n",
      "Epoch [3/5], Step [800/925], Loss: 0.5290\n",
      "Epoch [4/5], Step [200/925], Loss: 0.4136\n",
      "Epoch [4/5], Step [400/925], Loss: 0.2934\n",
      "Epoch [4/5], Step [600/925], Loss: 0.2942\n",
      "Epoch [4/5], Step [800/925], Loss: 0.2228\n",
      "Epoch [5/5], Step [200/925], Loss: 0.1807\n",
      "Epoch [5/5], Step [400/925], Loss: 0.1591\n",
      "Epoch [5/5], Step [600/925], Loss: 0.1570\n",
      "Epoch [5/5], Step [800/925], Loss: 0.1308\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_dl)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "    \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 200 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d5ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acc(dl):\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            n_correct += (predicted == labels).sum()\n",
    "            n_samples += predicted.size(0)\n",
    "\n",
    "        print(f\"acc : Got {n_correct} / {n_samples} with accuracy {float(n_correct)/float(n_samples)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0152913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : Got 91430 / 92439 with accuracy 98.91\n"
     ]
    }
   ],
   "source": [
    "check_acc(train_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3004ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : Got 91430 / 92439 with accuracy 98.91\n"
     ]
    }
   ],
   "source": [
    "check_acc(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454786f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_acc(val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29a6ab",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfe6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor(),transforms.Grayscale()])\n",
    "\n",
    "train_data = ImageFolder(TRAIN_DIRECTORY, transform=img_transform)\n",
    "val_data = ImageFolder(VAL_DIRECTORY, transform=img_transform)\n",
    "test_data = ImageFolder(TEST_DIRECTORY, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4db5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, batch_size=64, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_data, batch_size=64,shuffle=True, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d49c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e715771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e64a9a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "training_data = enumerate(train_dl)\n",
    "batch_idx, (images, labels) = next(training_data)\n",
    "print(images.shape) # Size of the image\n",
    "print(labels.shape) # Size of the labels\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d38ac1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.convolutional_layer = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=87),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional_layer(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear_layer(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f613d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (convolutional_layer): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Tanh()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): Tanh()\n",
      "  )\n",
      "  (linear_layer): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=84, out_features=87, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = LeNet5().to(device)\n",
    "print(model)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005faf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70919dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d3d424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+----------------+\n",
      "| Layer   | Input Shape   | Output Shape   |\n",
      "+=========+===============+================+\n",
      "| Conv1   | 1x32x32       | 6x28x28        |\n",
      "+---------+---------------+----------------+\n",
      "| AvgPool | 6x28x28       | 6x14x14        |\n",
      "+---------+---------------+----------------+\n",
      "| Conv2   | 6x14x14       | 16x10x10       |\n",
      "+---------+---------------+----------------+\n",
      "| AvgPool | 16x10x10      | 16x5x5         |\n",
      "+---------+---------------+----------------+\n",
      "| Conv3   | 400           | 120            |\n",
      "+---------+---------------+----------------+\n",
      "| FC1     | 120           | 84             |\n",
      "+---------+---------------+----------------+\n",
      "| FC2     | 84            | 87             |\n",
      "+---------+---------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "layers = [\n",
    "    [\"Layer\",\"Input Shape\",\"Output Shape\"],\n",
    "    [\"Conv1\",\"1x32x32\",\"6x28x28\"],\n",
    "    [\"AvgPool\",\"6x28x28\",\"6x14x14\"],\n",
    "    [\"Conv2\",\"6x14x14\",\"16x10x10\"],\n",
    "    [\"AvgPool\",\"16x10x10\",\"16x5x5\"],\n",
    "    [\"Conv3\",\"400\",\"120\"],\n",
    "    [\"FC1\",\"120\",\"84\"],\n",
    "    [\"FC2\",\"84\",\"87\"],\n",
    "]\n",
    "table = tabulate(layers, headers=\"firstrow\",tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a16268",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs =15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "320b49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 3.8337, Train Accuracy: 0.6562, Test Loss: 3.8278, Test Accuracy: 0.6609\n",
      "Epoch [2/15], Train Loss: 3.8285, Train Accuracy: 0.6614, Test Loss: 3.8233, Test Accuracy: 0.6655\n",
      "Epoch [3/15], Train Loss: 3.8210, Train Accuracy: 0.6685, Test Loss: 3.8171, Test Accuracy: 0.6731\n",
      "Epoch [4/15], Train Loss: 3.8143, Train Accuracy: 0.6753, Test Loss: 3.8081, Test Accuracy: 0.6810\n",
      "Epoch [5/15], Train Loss: 3.8066, Train Accuracy: 0.6833, Test Loss: 3.7994, Test Accuracy: 0.6903\n",
      "Epoch [6/15], Train Loss: 3.7992, Train Accuracy: 0.6904, Test Loss: 3.7924, Test Accuracy: 0.6960\n",
      "Epoch [7/15], Train Loss: 3.7937, Train Accuracy: 0.6957, Test Loss: 3.7903, Test Accuracy: 0.6990\n",
      "Epoch [8/15], Train Loss: 3.7904, Train Accuracy: 0.6992, Test Loss: 3.7880, Test Accuracy: 0.7022\n",
      "Epoch [9/15], Train Loss: 3.7853, Train Accuracy: 0.7042, Test Loss: 3.7809, Test Accuracy: 0.7082\n",
      "Epoch [10/15], Train Loss: 3.7807, Train Accuracy: 0.7085, Test Loss: 3.7772, Test Accuracy: 0.7121\n",
      "Epoch [11/15], Train Loss: 3.7765, Train Accuracy: 0.7129, Test Loss: 3.7714, Test Accuracy: 0.7173\n",
      "Epoch [12/15], Train Loss: 3.7716, Train Accuracy: 0.7176, Test Loss: 3.7695, Test Accuracy: 0.7201\n",
      "Epoch [13/15], Train Loss: 3.7674, Train Accuracy: 0.7217, Test Loss: 3.7653, Test Accuracy: 0.7240\n",
      "Epoch [14/15], Train Loss: 3.7652, Train Accuracy: 0.7240, Test Loss: 3.7624, Test Accuracy: 0.7269\n",
      "Epoch [15/15], Train Loss: 3.7613, Train Accuracy: 0.7275, Test Loss: 3.7606, Test Accuracy: 0.7287\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for images, labels in train_dl:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss = running_loss / len(train_data)\n",
    "    train_accuracy = correct_predictions / len(train_data)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dl:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track validation loss and accuracy\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss and accuracy\n",
    "    test_loss = test_loss / len(test_data)\n",
    "    test_accuracy = correct_predictions / len(test_data)\n",
    "\n",
    "    # Print progress for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc7319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8c06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "\n",
    "train_data = ImageFolder(TRAIN_DIRECTORY, transform=img_transform)\n",
    "val_data = ImageFolder(VAL_DIRECTORY, transform=img_transform)\n",
    "test_data = ImageFolder(TEST_DIRECTORY, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6162eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, batch_size=64, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_data, batch_size=64,shuffle=True, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f3e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65b9148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "training_data = enumerate(train_dl)\n",
    "batch_idx, (images, labels) = next(training_data)\n",
    "print(images.shape) # Size of the image\n",
    "print(labels.shape) # Size of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e40879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Download the pre-trained MobileNetV2 model\n",
    "model = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b521d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 87\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = torch.nn.Linear(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b27ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746cc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5dea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for images, labels in train_dl:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss = running_loss / len(train_data)\n",
    "    train_accuracy = correct_predictions / len(train_data)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dl:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track validation loss and accuracy\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss and accuracy\n",
    "    test_loss = test_loss / len(test_data)\n",
    "    test_accuracy = correct_predictions / len(test_data)\n",
    "\n",
    "    # Print progress for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb914739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
